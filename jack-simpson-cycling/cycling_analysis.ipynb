{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from website using scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://cycling.data.tfl.gov.uk/'\n",
    "page = requests.get(URL)\n",
    "\n",
    "#create bs4 object\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Webpage uses JS to load the table, so we will use selenium first to scrape the content and then BS4 to get links for files - before then using HTTP requests for the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out - the below code initially saved the flat HTML content in a html file, which is saved in the data folder\n",
    "\n",
    "# driver = webdriver.Edge()\n",
    "# driver.get(URL)\n",
    "# driver.set_window_position(0, 0)\n",
    "# driver.set_window_size(100000, 200000)\n",
    "# driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "# time.sleep(5) # wait to load\n",
    "\n",
    "# # now print the response\n",
    "# #print(driver.page_source)\n",
    "\n",
    "# soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# with open(\"data\\\\tfl_data.html\", \"w\") as file:\n",
    "#     file.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open html file of the tfl website\n",
    "\n",
    "with open('data\\\\tfl_data.html', 'r') as file:\n",
    "    html_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to BS4 object for scraping\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table with all files in\n",
    "\n",
    "table = soup.find(id=\"tbody-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all URLs from the table for download\n",
    "\n",
    "all_links = []\n",
    "\n",
    "for tr in table.find_all('tr'):\n",
    "    dl = tr.get('data-level')\n",
    "\n",
    "    #only get level 3 links\n",
    "    if dl == '3':\n",
    "        # get a href tag for download link\n",
    "        a_links = tr.find_all('a', href=True)\n",
    "        # only get csv files\n",
    "        if tr.find_all('td')[3].string == \"CSV file\":\n",
    "            # only add link where there is a link that exists\n",
    "            if len(a_links) > 0:\n",
    "                all_links.append(a_links[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the links that are just for the usage stats that are for years 2019-2021\n",
    "\n",
    "usage_links_all = []\n",
    "\n",
    "for l in all_links:\n",
    "    if l[32:43] == 'usage-stats' and (l[-6:-4] == '19' or l[-6:-4] == '20' or l[-6:-4] == '21'):\n",
    "        usage_links_all.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the first url which is data for 2018 to first day of 2019\n",
    "usage_links_all = usage_links_all[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all commented to reduce run time.\n",
    "# The below code requested all usage stats data and then saved the data in a csv file\n",
    "\n",
    "\n",
    "# # to allow for csv reading\n",
    "# storage_options = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# def merge_csv_data(urls):\n",
    "#     dfs = []\n",
    "#     for url in urls:\n",
    "#         # Read CSV data from URL\n",
    "#         df = pd.read_csv(url, storage_options=storage_options)\n",
    "#         # Append dataframe to list\n",
    "#         dfs.append(df)\n",
    "    \n",
    "#     # Concatenate all dataframes in the list into one dataframe\n",
    "#     merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "#     return merged_df\n",
    "\n",
    "# # List of URLs pointing to CSV files\n",
    "# urls = usage_links_all\n",
    "\n",
    "# # Call the function and get the merged dataframe\n",
    "# merged_dataframe = merge_csv_data(urls)\n",
    "\n",
    "# merged_dataframe.to_csv('data\\\\all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from saved CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\\\all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31348502, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Very large dataset, 31 million rows of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            int64\n",
       "Rental Id             int64\n",
       "Duration              int64\n",
       "Bike Id               int64\n",
       "End Date             object\n",
       "EndStation Id         int64\n",
       "EndStation Name      object\n",
       "Start Date           object\n",
       "StartStation Id       int64\n",
       "StartStation Name    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnamed:0\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start and end dates to DateTime values\n",
    "df['Start Date'] = pd.to_datetime(df['Start Date'], dayfirst=True)\n",
    "df['End Date'] = pd.to_datetime(df['End Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to create some features from our dataset\n",
    "  - Start and end date columns\n",
    "  - Time of journey\n",
    "  - Borough / Area of start and end\n",
    "  - Weekday / Weekend\n",
    "  - Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First rename columns from Start / End Date to Start / End DateTime\n",
    "df.rename(columns = {\n",
    "    'Start Date' : 'Start DateTime',\n",
    "    'End Date' : 'End DateTime'\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date object from datetime\n",
    "df['Start Date'] = df['Start DateTime'].dt.date\n",
    "df['End Date'] = df['End DateTime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and End Time of Day\n",
    "df['Start Time'] = df['Start DateTime'].dt.time\n",
    "df['End Time'] = df['End DateTime'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get borough string\n",
    "\n",
    "def get_area(input) -> str:\n",
    "    try:\n",
    "        return input.split(',')[1][1:]\n",
    "    except IndexError:\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the area values for analysis\n",
    "\n",
    "input_array_start = df['StartStation Name'].values\n",
    "input_array_end = df['EndStation Name'].values\n",
    "\n",
    "#for performance\n",
    "get_area_vectorized = np.vectorize(get_area)\n",
    "\n",
    "result_start_areas = get_area_vectorized(input_array_start)\n",
    "result_end_areas = get_area_vectorized(input_array_start)\n",
    "\n",
    "result_series_start_areas = pd.Series(result_start_areas)\n",
    "result_series_end_areas = pd.Series(result_end_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results from vectorized function as features\n",
    "df['Start Area'] = result_series_start_areas.values\n",
    "df['End Area'] = result_series_end_areas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneccesary columns (ID columns)\n",
    "df.drop(columns=[\n",
    "    'Rental Id',\n",
    "    'Bike Id',\n",
    "    'EndStation Id',\n",
    "    'StartStation Id'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>End DateTime</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start DateTime</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Start Area</th>\n",
       "      <th>End Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660</td>\n",
       "      <td>2019-01-02 17:47:00</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2019-01-02 17:36:00</td>\n",
       "      <td>Stamford Street, South Bank</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>17:36:00</td>\n",
       "      <td>17:47:00</td>\n",
       "      <td>South Bank</td>\n",
       "      <td>South Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "      <td>2019-01-06 18:14:00</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2019-01-06 18:11:00</td>\n",
       "      <td>Empire Square, The Borough</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>18:11:00</td>\n",
       "      <td>18:14:00</td>\n",
       "      <td>The Borough</td>\n",
       "      <td>The Borough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960</td>\n",
       "      <td>2019-01-02 14:49:00</td>\n",
       "      <td>Waterloo Station 1, Waterloo</td>\n",
       "      <td>2019-01-02 14:33:00</td>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>14:49:00</td>\n",
       "      <td>Sloane Square</td>\n",
       "      <td>Sloane Square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>2019-01-04 12:54:00</td>\n",
       "      <td>Empire Square, The Borough</td>\n",
       "      <td>2019-01-04 12:52:00</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>12:52:00</td>\n",
       "      <td>12:54:00</td>\n",
       "      <td>Borough</td>\n",
       "      <td>Borough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>2019-01-05 16:03:00</td>\n",
       "      <td>Empire Square, The Borough</td>\n",
       "      <td>2019-01-05 16:01:00</td>\n",
       "      <td>Bricklayers Arms, Borough</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>16:01:00</td>\n",
       "      <td>16:03:00</td>\n",
       "      <td>Borough</td>\n",
       "      <td>Borough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration        End DateTime               EndStation Name  \\\n",
       "0       660 2019-01-02 17:47:00     Bricklayers Arms, Borough   \n",
       "1       180 2019-01-06 18:14:00     Bricklayers Arms, Borough   \n",
       "2       960 2019-01-02 14:49:00  Waterloo Station 1, Waterloo   \n",
       "3       120 2019-01-04 12:54:00    Empire Square, The Borough   \n",
       "4       120 2019-01-05 16:03:00    Empire Square, The Borough   \n",
       "\n",
       "       Start DateTime              StartStation Name  Start Date    End Date  \\\n",
       "0 2019-01-02 17:36:00    Stamford Street, South Bank  2019-01-02  2019-01-02   \n",
       "1 2019-01-06 18:11:00     Empire Square, The Borough  2019-01-06  2019-01-06   \n",
       "2 2019-01-02 14:33:00  Sedding Street, Sloane Square  2019-01-02  2019-01-02   \n",
       "3 2019-01-04 12:52:00      Bricklayers Arms, Borough  2019-01-04  2019-01-04   \n",
       "4 2019-01-05 16:01:00      Bricklayers Arms, Borough  2019-01-05  2019-01-05   \n",
       "\n",
       "  Start Time  End Time     Start Area       End Area  \n",
       "0   17:36:00  17:47:00     South Bank     South Bank  \n",
       "1   18:11:00  18:14:00    The Borough    The Borough  \n",
       "2   14:33:00  14:49:00  Sloane Square  Sloane Square  \n",
       "3   12:52:00  12:54:00        Borough        Borough  \n",
       "4   16:01:00  16:03:00        Borough        Borough  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
